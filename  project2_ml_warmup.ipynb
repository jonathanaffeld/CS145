{"cells":[{"cell_type":"markdown","metadata":{"id":"jMKwOgSYfHBU"},"source":["# CS145: Project 2 | ML Warmup (10 points)\n","---\n","Notes (read carefully!):\n","* Be sure you read the instructions on each cell and understand what it is doing before running it.\n","* Don't forget that if you can always re-download the starter notebook from the course website if you need to.\n","* You may create new cells to use for testing, debugging, exploring, etc., and this is in fact encouraged! Just make sure that the final answer for each question is **in its own cell** and **clearly indicated**.\n","* Colab will not warn you about how many bytes your SQL query will consume.  **Be sure to check on the BigQuery UI first before running queries here!**\n","* This project may be done alone or in pairs.\n","* See the assignment handout for submission instructions.\n","* Due date is same date as project due date (November 29th, 11:59PM)"]},{"cell_type":"markdown","metadata":{"id":"NesZcATkfnq0"},"source":["## Setting Up BigQuery and Dependencies\n"]},{"cell_type":"markdown","metadata":{"id":"pOutY8Csskgi"},"source":["Run the cells below (shift + enter) to authenticate your project.\n","\n","Note that you need to fill in the `project_id` variable with the Google Cloud project id you are using for this course.  You can see your project ID by going to https://console.cloud.google.com/cloud-resource-manager"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyFqjDKmfSkU"},"outputs":[],"source":["# Run this cell to authenticate yourself to BigQuery\n","from google.oauth2 import service_account\n","key_path = './cs145-project2-406000-9a59fc7c0b3d.json'\n","credential = service_account.Credentials.from_service_account_file(key_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L-LT4rEko06"},"outputs":[],"source":["# Initialize BiqQuery client\n","from google.cloud import bigquery\n","%load_ext google.cloud.bigquery\n","%env GOOGLE_APPLICATION_CREDENTIALS=$key_path\n","project_id = \"cs145-project2-406000\"\n","client = bigquery.Client(credentials=credential, project=project_id)"]},{"cell_type":"markdown","metadata":{"id":"pInaYkgjfwZt"},"source":["# Overview\n","\n","This part of Project 2 is meant serve as a brief tutorial for Machine Learning with BigQuery, since you will be using BigQuery Prediction in the final portion of your explorations.\n","\n","Don't worry if you've never studied Machine Learning before. This notebook will guide you through everything you need to know to be successful in the open-ended part of Project 2."]},{"cell_type":"markdown","metadata":{"id":"Z9nrJtByq6Q-"},"source":["In the next two sections, we'll give you a bird's eye intro to machine learning and a primer on how BigQuery makes machine learning easy. In the third and last section, you'll walk through an example of how to train and use a machine learning model in BigQuery."]},{"cell_type":"markdown","metadata":{"id":"_xCUsFh8iyho"},"source":["# Section 1: Machine Learning in a Nutshell\n","\n","Basic Machine Learning tasks can be framed in terms of **inputs** $X$, **target values** $Y$ (sometimes called labels), **training data** (pairs of observed data points $(x_i, y_i)$), and a function $h:X \\rightarrow Y$ historically called the **hypothesis function** that maps inputs to target values.  \n","\n","Given these primitives, we can think of the canonical Machine Learning task as follows:\n","\n","> Given that I've seen a ton of training data $(x_1, y_1), ..., (x_m, y_m)$, how can I come up with a good function $h$ so that on an *unseen* input value $x_{m+1}$, the value of $h(x_{m+1})$ is a good \"prediction\" $y_{m+1}$?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"faHlhArpv1Ee"},"source":["#### Example 1: Three Point Shots\n","Say elements of $X$ are the number of three point shots scored by a team in a basketball game, and elements of $Y$ are $0$ or $1$ indicating whether that team lost or won the game.  Our training data could look like this:\n","​\n","> $T = \\{(2, 0), (3, 0), (6, 0), (5, 0), (10, 0), (11, 0), (5, 1), (15, 1), (18, 0), (17, 1), (16, 1), (16, 1)\\}$\n","\n","\n","In this case, we'd *train* a machine learning model on $T$ to effectively generate an $h$ that would give us reasonable values of $y$ for unseen values of $x$, i.e., predict whether a game was won or not based on how many three pointers were scored on that game.  For example, we might expect that $h(1) \\approx 0$, and\n","$h(20) \\approx 1$. Note that in this case, we'd like $h$ to output not only a 0 or 1 but a *probability* for how likely a game is to be won, hence the approximate equalities.\n","​"]},{"cell_type":"markdown","metadata":{"id":"_MwXnNwUv93x"},"source":["#### Example 2: GitHub\n","\n","For a richer example, let's say we are trying to predict how many *forks* (i.e., copies of the repo by GitHub users besides the original owner) a Github repo will have at some point in time -- here $Y$ will represent the number of forks of a repo. As you might have expect, such questions are usually not easily answerable with only one (or two) simple statistics of a Github repo.  We usually want to think about several *features* together.  What are the watch and star count of the repo? How many contributors does the repo have? How many files does the repo have? What is the age of the repo in years?  \n","\n","The values in $X$ *need not be single real numbers*, they can be lists of real numbers as well, and we can use feature engineering to come up with these feature lists.\n","\n","*Feature engineering* is the most informal process by which we use domain-knowledge to extract numerical features from some entity (e.g., a GitHub repo in this example), to provide them as training data to a machine learning model.\n","\n","Here is how a simple feature engineering process for predicting the fork count of a GitHub repo may pan out:\n","\n","##### Simple feature engineering process\n","\n","1. Using domain knowledge, you hypothesize that watch count, star count, number of commits, and age of the repo will probably be good indicators of its fork count.  You also toss in the average commit length of the repo because you know it has some non-trivial relationship with watch count based on anecdotal evidence from a certain project in your friend's database course.\n","2. You write some code in your favorite programming language (or SQL if using BigQuery!) to extract these five features from your set of 1,000 GitHub repos, creating 1,000 tuples that look like this:\n","\n","> $((45, 100, 200, 2.4, 127.65), 30), ((65, 302, 100, 1.2, 164.1), 132) \\dots $\n","\n","3. You train your model on this data and evaluate it on another 100 repos **which your model has not yet seen**.  If the quality of your results (the accuracy of your predictions) is not so good, you may attempt to improve the quality of your features. If performance is good, you are done and have a decent model!\n","\n","4. If you think the current features you thought about are not good enough, you can go back to 1 and brainstorm more."]},{"cell_type":"markdown","metadata":{"id":"E6AGrUmvRMab"},"source":["Once you have honed in on a good set features which you have trained with and evaluated, you can now predict using your model. This should be done on an additional test dataset that **your model has also not yet seen**. Why is this part important (i.e., why can't we test it on data it has already seen)?"]},{"cell_type":"markdown","metadata":{"id":"cpBb4DoSE3zG"},"source":["### Evaluating your Models\n","\n","In Example 2, we said that the feature engineering process involves a key step in which you *evaluate* how good your model (aka hypothesis function $h$) is doing.  Usually this consists of:\n","\n","1. Running your hypothesis function $h$ on a set of inputs $X$ which you have not already seen to get outputs $h(x_{m+1}), \\dots, h(x_{m+k})$\n","2. Comparing how close your predicted values are to the ground-truth labels $y_{m+1}, \\dots, y_{m+k}$ using a reasonable statistical metric(s).\n","\n","The \"reasonable statistical metric\" varies depending on the nature of your labels.\n","\n","Here's a very brief overview of when you might want to use different metrics:\n","* **Accuracy** - when your classes are balanced (roughly same number of examples expected for each category)\n","* **F1-score** - when your classes are very unbalanced (some categories are expected to have way more examples than other categories)\n","* **Recall** - when you are more willing to have false positives than false negatives (e.g., predicting rare cancer - you'd rather have a false alarm than miss an actual case)\n","* **Precision** - when you are more willing to have false negatives than false positives (e.g., predicting spam emails - you'd rather have some spam in your inbox than have important emails go to spam)\n","* **RMSE (root mean squared error)** - when trying to predict a real value\n","* **AUC ROC score** - when classes are balanced and you care equally about positive and negative classes. It is a good measure of how well the model separates classes.\n","\n","There are many more ways to evaluate models, but deeper discussion is beyond the scope of this assignment and course."]},{"cell_type":"markdown","metadata":{"id":"5yblSw7mUPER"},"source":["### Data Splits\n","\n","Overall, when doing machine learning, you should have three datasets:\n","* **Training dataset** - the bulk of your data, which you use to let your model learn a hypothesis function $h$\n","* **Validation dataset** - a small portion of your data, used to evaluate your trained model as you try out different features and other possible hyperparameters.\n","* **Test dataset** - a small portion of your data, used to evaluate your **final model** when you are done picking features and tuning your model. You should not be running any models on this data to help choose relevant features.\n","\n","Common splits for machine learning datasets are to take 80% of data for training, 10% for validation, and 10% for testing, but many other splits are acceptable depending on how much data is available. Note that your testing data should never be \"too small\" that it doesn't adequately judge the success of your model (for example, 4 data points). If you ever run into these kinds of issues for your project, you probably don't have enough data!"]},{"cell_type":"markdown","metadata":{"id":"hmPqespz4qP2"},"source":["## Types of Models\n","​\n","BigQuery supports three types of models: *linear regression, binary logistic regression, and multiclass logistic regression*.\n","\n","\n","* A *linear regression model* predicts a number, i.e., $Y = \\mathbb{R}$.\n","\n","\n","* A *binary logistic regression model* makes a binary prediction by giving the confidence of an event, e.g., is an email spam or not?\n","\n","* A *multiclass logistic regression model* is a generalization of the binary logistic regression model.  E.g., what is the sentiment bucket of a sentence, from 1 (negative) to 5 (positive).\n","\n","Example 1 above is a binary logistic regression model, and Example 2 is a linear regression model. You can use any of these three models in your project for making predictions using machine learning."]},{"cell_type":"markdown","metadata":{"id":"XvnCsAp6CiEq"},"source":["Besides BigQuery's offered set of models, we can construct our own (simpler) machine learning baseline for this project using simple database queries (just like we have been doing throghout this course!). Put simply, if we are given a data point $x_t$ to make a prediction, we will go through our dataset, compute which $k$ data points are most **similar** to $x_t$, and take an average or majority vote from the target values of these $k$ similar data points.\n","\n","Below, we present the formal algorithm for $k$-nearest neighbours for regression or classification. Suppose we are given a data point $x_t$ either for regression or classification and a dataset ($X, Y$) of size $N$ containing features:\n","\n","1. Using the $L_2$ (or Euclidean) distance, compute the set $S ⊂ [1, N]$ with size $k$ containing the indices $i \\in [1, N]$ corresponding to the $k$-smallest values of $||X_i - x_t||_2$ (note that this is the same as the root-mean squared error).\n","2. For each $i \\in S$, select the $k$ chosen values of $Y_i$.\n","3. For a regression task, return the average of the set of $Y_i$ from the previous step or for a classification task, return the majority vote.\n","\n","As a concrete example below, consider the dataset below with 4 data points $(x, y)$, where we would like to predict $y$ given $x$ (regression):\n","- $(x_1, y_1) = (3, 4)$\n","- $(x_2, y_2) = (1, 2)$\n","- $(x_3, y_3) = (9, 10)$\n","- $(x_4, y_4) = (11, 13)$\n","\n","**Example**\n","\n","Let's try to apply $k$-nearest neighbours for regression with $k = 2$! Suppose we want to make predictions for the point $x_t = 2$. Our closest neighbours are $x_1$ and $x_2$ since they are one unit away in $L_2$ distance from $x_t$. This means that we would select $y_1$ and $y_2$, outputting $\\frac{y_1 + y_2}{2} = 3$.\n","\n","As an ungraded exercise, what would our prediction for $x_t = 10$ be? Now, consider the cost of making a prediction for a single $x_t$ for this dataset containing 4 data points with $k = 2$? How expensive would it be to classify one data point given a dataset of size $N$ with arbitrarily large $k$ (worst case)?\n","\n","*Hint*: How can we algorithmically find the $k$-closest points to a give point? What is the time complexity of this task? Do not worry about optimizing the algorithm significantly!"]},{"cell_type":"markdown","metadata":{"id":"5NXULYvVNAB9"},"source":["If you have not already studied machine learning and are interested in digging into more details, reading section 1 of the CS229 notes [here](http://cs229.stanford.edu/notes/cs229-notes1.pdf) will cover the basic topics discussed here and expand on them. However, the information in this notebook will be sufficient to complete Project 2."]},{"cell_type":"markdown","metadata":{"id":"5zbORTWqrPS1"},"source":["# Section 2: BigQuery and ML\n","\n","In the previous section, we did not cover how the hypothesis function $h$ is actually generated from training data.  Luckily for us, BigQuery abstracts the details of this process away from us and instead exposes a nice SQL interface for ML which we already know how to work with!\n","\n","Machine Learning in BigQuery consists of three steps: creating a model, evaluating the model, and using the model to make predictions."]},{"cell_type":"markdown","metadata":{"id":"ObgL_ttqF7LW"},"source":["#### Creating a Model\n","\n","This step consists of telling BigQuery that you want to create a model.  You tell BigQuery what type of model you want to create, and you write SQL to gather the features and ground-truth values for the model.\n","\n","The create model statement could look like this:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"exVy7D1bJB6m"},"outputs":[],"source":["# Don't run me!  My tables don't exist. I'm just here as an example.\n","%%bigquery --project $project_id\n","\n","CREATE MODEL `my_awesome_model`\n","OPTIONS(model_type='logistic_reg') AS\n","SELECT\n","  IF(my_awesome_database.ground_truth IS NULL, 0, 1) AS label,  # if ground_truth is NULL then label is 0, else 1\n","  IFNULL(my_awesome_database.feature1, \"\") AS feature1,         # converts NULL values to \"\"\n","  my_awesome_database.feature2 AS feature2,\n","  my_awesome_database.feature3 AS feature3,\n","  my_awesome_database.feature2 * my_awesome_database.feature3 AS feature4\n","FROM\n","  `my_awesome_database`\n","WHERE\n","  my_awesome_database.date BETWEEN 2010 AND 2015"]},{"cell_type":"markdown","metadata":{"id":"oTEg5g9JJiXR"},"source":["One thing to note: `CREATE MODEL` will fail if the model with that name has already been created. If you're retraining your model, for example, you'll want to use `CREATE OR REPLACE MODEL` as the first line instead.\n","\n","See this page for documentation: https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create"]},{"cell_type":"markdown","metadata":{"id":"OOCRI0qoF7xH"},"source":["#### Evaluating the Model\n","\n","Once you've created your model, BigQuery has already trained it for you -- you already have a $h$ at your disposal ready to evaluate!  We evaluate $h$ by asking BigQuery to predict the $Y$ values of **new data unseen by the model** and compare them to ground-truth values.\n","\n","To evaluate a model you'd do something like this:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ae4ETQDAKJzA"},"outputs":[],"source":["# Don't run me!  My tables don't exist. I'm just here as an example.\n","%%bigquery --project $project_id\n","\n","SELECT\n","  *\n","FROM\n","  ML.EVALUATE(MODEL `my_awesome_model`, (\n","SELECT\n","  IF(my_awesome_database.ground_truth IS NULL, 0, 1) AS label,\n","  IFNULL(my_awesome_database.feature1, \"\") AS feature1,\n","  my_awesome_database.feature2 AS feature2,\n","  my_awesome_database.feature3 AS feature3,\n","  my_awesome_database.feature2 * my_awesome_database.feature3 AS feature4\n","FROM\n","  `my_awesome_database`\n","WHERE\n","  my_awesome_database.date BETWEEN 2016 AND 2017))"]},{"cell_type":"markdown","metadata":{"id":"RrMgxk9KK5Pf"},"source":["Note that we are evaluating on data between 2016 and 2017, even though we trained on data between\n","2010 and 2015.  **This is important!!**  If we did not do this, we would be \"cheating\" since the model has already\n","seen a training value corresponding to the one you are trying to evaluate.  If the model was a simple lookup\n","table, it would get 100% accuracy on everything it's already seen trivially. Also, we'll generally use a much larger amount of data for training than for evaluating or testing."]},{"cell_type":"markdown","metadata":{"id":"8SKiLOwLLLuo"},"source":["See this page for documentation: https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-evaluate.  Note the `ML.EVALUATE` function is one of three functions you can use to evaluate your model, depending on your task."]},{"cell_type":"markdown","metadata":{"id":"nkdTSLs3F78X"},"source":["#### Exercising the Model\n","\n","If your model achieves good evaluation metrics (while this is subjective, an accuracy of 50-55%, for example, is not good for a classification task with two classes), you can now utilize your model to predict values. Again, this should be done on data that the model has not seen.\n","\n","Assuming you have a trained model, you can predict values like this:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRYSk65gLnhk"},"outputs":[],"source":["# Don't run me!  My tables don't exist. I'm just here as an example.\n","%%bigquery --project $project_id\n","\n","SELECT\n","  my_awesome_database.key,\n","  predicted_label\n","FROM\n","  ML.PREDICT(MODEL `my_awesome_model`, (\n","SELECT\n","  IFNULL(my_awesome_database.feature1, \"\") AS feature1,\n","  my_awesome_database.feature2 AS feature2,\n","  my_awesome_database.feature3 AS feature3,\n","  my_awesome_database.feature2 * my_awesome_database.feature3 AS feature4\n","FROM\n","  `my_awesome_database`\n","WHERE\n","  my_awesome_database.date BETWEEN 2018.01 AND 2018.02))"]},{"cell_type":"markdown","metadata":{"id":"L-H74FvpMSnD"},"source":["See this page for documentation: https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-predict."]},{"cell_type":"markdown","metadata":{"id":"2Fg_3vs9F8du"},"source":["For more details and an end-to-end example in BigQuery, read the following article: https://cloud.google.com/bigquery/docs/create-machine-learning-model."]},{"cell_type":"markdown","metadata":{"id":"C8E_M30210db"},"source":["#### Constructing a KNN Baseline\n","\n","In the final project, you will be required to construct a database-only baseline (not linear or logistic regression). We recommend that you implement the $k$-nearest neighbours (KNN) algorithm for regression or classification using SQL.\n","\n","Below, we have shown code for KNN in Python to demonstrate the algorithm (**note: you must use SQL in the final project for credit, not Python!**)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTDk72EA2eKy"},"outputs":[],"source":["# Feel free to try out the KNN and change the parameters below!\n","# What happens when you increase k? How about the dataset size?\n","# What if k = 1?\n","\n","import numpy as np\n","from statistics import mode\n","\n","np.random.seed(42)\n","\n","dataset_size, num_features = 100000, 2\n","k = 10\n","classify = False\n","\n","def generate_fake_data(f, classify = True, noise = 1e-2):\n","    X = np.random.normal(0, 1, size = (dataset_size, num_features))\n","    y = f(X) + np.random.normal(0, noise, size = (dataset_size, ))\n","    if classify:\n","        y = np.sign(y)\n","    return X, y\n","\n","def find_closest_k(X, x_t):\n","    distances = []\n","    for x_i in X:\n","        distances.append(np.linalg.norm(x_t - x_i))\n","    return np.argsort(distances)[:k]\n","\n","def select_target_value(Y, k_idx, classify = True):\n","    if classify:\n","        return mode(Y[k_idx])\n","    return np.mean(Y[k_idx])\n","\n","def initialize_knn(X, Y, classify = True):\n","    def predict(x_t):\n","        k_idx = find_closest_k(X, x_t)\n","        return select_target_value(Y, k_idx, classify)\n","    return predict\n","\n","def true_prediction_error(f, x_t, y_hat):\n","    return np.abs(f(x_t) - y_hat)\n","\n","theta = np.random.uniform(size = (num_features, ))\n","f = lambda x: x @ theta\n","X, Y = generate_fake_data(f, classify = classify)\n","knn = initialize_knn(X, Y, classify = classify)\n","\n","# Making a prediction on a data point.\n","print(\"Prediction on 1st data point:\", knn(X[0]))\n","print(\"Actual target for 1st data point:\", Y[0], \"\\n\")\n","\n","# Making a prediction on an unseen (test) data point.\n","x_t = np.random.normal(0, 1, (num_features, ))\n","print(\"Prediction on test data point:\", knn(x_t))\n","if classify:\n","    print(\"Actual target for test data point:\", np.sign(f(x_t)))\n","else:\n","    print(\"Actual target for test data point:\", f(x_t))"]},{"cell_type":"markdown","metadata":{"id":"lg4K0aisqm3x"},"source":["# Section 3: Now it's Your Turn!\n","\n","Let's now dive into an exercise using BigQuery and ML! This is a fairly simple warm-up problem to help you gain hands-on experience working with BQML. You'll get to dive into much more depth with your open-ended project!  You'll be going through the three steps described in the previous section on your own.\n","\n","For this problem, we're going to be working with CS145's copy of the Austin bikeshare dataset. Take a moment to familiarize yourself with the data we have at hand.\n","\n","You can access the dataset by starring `cs145-fall2023` (see how to star a project by [name here](https://static.us.edusercontent.com/files/GLGfU5yovkpVGZIA5Necd1pQ)) and accessing the `austin_bikeshare` project.\n","- Click on the dataset. You’ll see a brief description of what information the dataset contains, as well as a brief overview of information such as the dataset size.\n","\n","\n","Notice we have various pieces of information about each trip - for example, the stations where the biker started and ended, with the corresponding latitude/longitude, the date of the ride, the subscriber type, and the duration of the trip in minutes.\n"]},{"cell_type":"markdown","metadata":{"id":"391ISLXuKZtB"},"source":["Our goal in this exercise will be the following:\n","\n","> *Given attributes about a ride, can we predict whether a bike ride will be a \"quick\" ride?  Let's define a \"quick\" ride as a ride that takes less than 15 minutes.*\n","\n","Note this is a *binary logistic regression task*, or classification task, where, given attributes about a ride, we predict one of two labels: 1 = quick (< 15 minutes); 0 = not quick (>= 15 minutes).\n","\n","Once we've trained our model, we can then use it to help predict on unlabeled data. In particular, we can use it to help fill in missing data - some bike rides have a different start/end station, but have a duration of 0 minutes (likely missing data).\n","\n","Let's dive in!\n"]},{"cell_type":"markdown","metadata":{"id":"5Bg24pgTQlpN"},"source":["### Step 1: Look at the data (1 point)\n","\n","In any ML task, it's important to first explore the data. Investigating correlations between attributes can help you determine which attributes may be useful as training features, and will be important for your final project. And, looking into the distribution of labels, you want the prediction to give you a better understanding of the distribution of your data (such as whether your dataset is *balanced*). For this exercise, we'll dig into the latter."]},{"cell_type":"markdown","metadata":{"id":"BPEQw4IcdOgY"},"source":["**a) What percentage of rides are \"quick\"? Recall that we have: quick ride: < 15 minutes; not quick: >= 15 minutes. Filter out rides with a duration of 0 minutes.**\n","\n","Hint: [COUNTIF](https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#countif) may be helpful."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":573,"status":"ok","timestamp":1700701386014,"user":{"displayName":"Leon Thomas MacAlister","userId":"01188578658792519443"},"user_tz":300},"id":"JqHC8-NAVm5v","outputId":"20649d6d-7d82-4f6a-b5a1-74e537f3402d"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","WITH fast_trips as (\n","  SELECT trip_id\n","  FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips`\n","  WHERE duration_minutes < 15 AND duration_minutes != 0\n",")\n","\n","SELECT ROUND(count(*) / (SELECT count(*) FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips`) * 100, 2) as quick_percentage\n","FROM fast_trips"]},{"cell_type":"markdown","metadata":{"id":"J4wXw4xUe8XP"},"source":["**b) What percentage of rides have a different start/end station, but have a value of 0 for their duration? How many rides is this? Write a query that returns the count in one column and the percentage in another. The denominator for the percentage should be all rides, regardless of duration.**\n","\n","Hint: [COUNTIF](https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#countif) may be helpful.\n","\n","Hint: `end_station_id` is a string instead of an integer. Use `CAST(end_station_id AS INT64)` as needed in this and future questions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slr4JOFTVt0N"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","WITH diff_start as (\n","  SELECT trip_id\n","  FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips`\n","  WHERE start_station_id != CAST(end_station_id AS INT64) AND duration_minutes = 0\n",")\n","\n","SELECT ROUND(count(*) / (SELECT count(*) FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips`) * 100, 2) as diff_percentage, count(*) as diff_count\n","FROM diff_start"]},{"cell_type":"markdown","metadata":{"id":"lLY2CfJ7RWcT"},"source":["### Step 2: Create a dataset to store the model\n","\n","When you create and train a model, BigQuery will store the model in a dataset. Before training, you'll first need to create a new empty dataset. Note that you only need to do this step once. If you later update your model, it can replace the existing one.\n","\n","You can also do this step in the UI.\n","\n","Let's call our dataset `bqml_bikeshare`. After either running the cell below, or creating the dataset with the BigQuery UI, you should see the dataset name appear in the left column of the UI."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"elapsed":214,"status":"error","timestamp":1700701181173,"user":{"displayName":"Leon Thomas MacAlister","userId":"01188578658792519443"},"user_tz":300},"id":"CMlA4qtYSnH8","outputId":"36efb0c0-4e5d-423c-b980-dbe79e2299eb"},"outputs":[],"source":["# Run this cell to create a dataset to store your model, or create in the UI\n","\n","model_dataset_name = 'bqml_bikeshare'\n","\n","dataset = bigquery.Dataset(client.dataset(model_dataset_name))\n","dataset.location = 'US'\n","client.create_dataset(dataset)"]},{"cell_type":"markdown","metadata":{"id":"SgyJkl_LQvj9"},"source":["### Step 3: Extract training data from BigQuery (2 points)\n","\n","**Write a SQL query that extracts training data from the dataset. These are features that you want to feed into your model. For this part, you do not need to do feature engineering - you can simply pull raw features from the tables that you think may be helpful.**\n","\n","Your query should return a column called `label` with the target label value (our \"Y\" value), and additional columns for some features you want to use (our \"X\" values).  Note:\n","- recall: `label` value is 1 for quick rides (< 15 minutes), and 0 otherwise (>= 15 minutes)\n","- duration_minutes cannot be a training feature - we're trying to predict (a boolean version of) this\n","- filter out any rides with a duration of 0 minutes\n","\n","Display the first 10 rows of the table returned by your query.\n","\n","Hint: For information about extracting values from a timestamp, refer to https://cloud.google.com/bigquery/docs/reference/standard-sql/timestamp_functions#extract"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2Fd92Ch4fpz"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","SELECT bikeid, start_station_name, end_station_name, EXTRACT(TIME FROM start_time) AS time, EXTRACT(DAYOFWEEK FROM start_time) AS day, EXTRACT(MONTH FROM start_time) AS month, EXTRACT(YEAR FROM start_time) AS year, subscriber_type, IF(duration_minutes < 15, 1, 0) AS label\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips`\n","WHERE duration_minutes > 0\n","LIMIT 10"]},{"cell_type":"markdown","metadata":{"id":"qlXdPkgiVnfX"},"source":["### Step 4: Train a simple model (1 point)"]},{"cell_type":"markdown","metadata":{"id":"hxcxZ7xOVqtz"},"source":["**First, an important note:**  it's important to have separate datasets to train, evaluate, and finally test your model. We'll want 3 different subsets of data:\n","\n","1. **Training set**: used to train a model.\n","  - we'll train on rides before 2017 (start_time < '2017-01-01'), with duration time  > 0\n","2. **Evaluation set**: used to evaluate model after training. This should not be data used during training. It can be used multiple times to evaluate and compare the performance of different models.\n","  - we'll evaluate on the next 5 months (start_time between  '2017-01-01' and '2017-06-01'), with duration time > 0\n","3. **Test set**: *should only be used once at the end of your entire training process* to say how your model does on real data. This should not be the same as either training or eval data. Using the test set to tune your model is bad, since it means you are starting to overfit your model (i.e., making your model artificially good on a certain dataset at the possible expense of it doing poorly on new data) to that test set as well.\n","  - we'll test on the 5 months after that (start_time between  '2017-06-01' and '2017-11-01'), with duration time > 0\n","  \n","Note that for all these datasets, we'll filter out rides with duration time = 0. For the purposes of this problem, we'll consider this to be incomplete data."]},{"cell_type":"markdown","metadata":{"id":"TdHOdKYdV-n2"},"source":["Now, let's go ahead and train a simple model. **Create a model, using the query you wrote above to tell the model what features and ground-truth labels to use.** Remember that we're training only on rides before 2017 (start_time < '2017-01-01'), and with a duration time > 0."]},{"cell_type":"markdown","metadata":{"id":"rRUB3YafONO4"},"source":["**Note**: it may take a few minutes to run the query. Also, you may get the error `Table has no schema: call 'client.get_table()'`. This is because notebook cells try to print out the table returned from a SQL query, but the query to create/train a model doesn't return any table at all, so the notebook complains. The model is still trained successfully though. You may ignore this, and can click the (X) in the top left of the output to clear the error message."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWz9D7HujGVE"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","\n","CREATE OR REPLACE MODEL `bqml_bikeshare.bikeshare_model`\n","OPTIONS(model_type='logistic_reg') AS\n","SELECT bikeid, start_station_name, end_station_name, EXTRACT(TIME FROM start_time) AS time, EXTRACT(DAYOFWEEK FROM start_time) AS day, EXTRACT(MONTH FROM start_time) AS month, EXTRACT(YEAR FROM start_time) AS year, subscriber_type, IF(duration_minutes < 15, 1, 0) AS label\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips`\n","WHERE duration_minutes > 0 AND EXTRACT(DATE FROM start_time) < '2017-01-01'"]},{"cell_type":"markdown","metadata":{"id":"rvUv5cq0CD-6"},"source":["You can get training statistics on your model by running the following cell:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wsXSNKUlCDOD"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# Run cell to view training stats\n","\n","SELECT\n","  *\n","FROM\n","  ML.TRAINING_INFO(MODEL `bqml_bikeshare.bikeshare_model`)"]},{"cell_type":"markdown","metadata":{"id":"cg0fe_zRz3a7"},"source":["### Step 5: Evaluate (1 point)\n","\n","**Evaluate your model on unseen evaluation data.**\n","\n","Recall for our evaluation set, we're using the 5 months following what we trained on  (use: start_time between '2017-01-01' and  '2017-06-01'), with duration time > 0.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHAkE5j_YgB1"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","SELECT\n","  *\n","FROM\n","  ML.EVALUATE(MODEL `bqml_bikeshare.bikeshare_model`, (\n","SELECT bikeid, start_station_name, end_station_name, EXTRACT(TIME FROM start_time) AS time, EXTRACT(DAYOFWEEK FROM start_time) AS day, EXTRACT(MONTH FROM start_time) AS month, EXTRACT(YEAR FROM start_time) AS year, subscriber_type, IF(duration_minutes < 15, 1, 0) AS label\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips`\n","WHERE duration_minutes > 0 AND EXTRACT(DATE FROM start_time) BETWEEN '2017-01-01' AND '2017-06-01'))"]},{"cell_type":"markdown","metadata":{"id":"s7hde4Ujz-RR"},"source":["### Step 6: Improving our model (3 points)\n","\n","In general, we can't just throw raw data into the model and expect it to work: in practice, you'll iterate on improving your features and re-training/re-evaluating your model. Let's try the following: add engineered features -> re-train model -> re-evaluate model.\n","\n","**a) Let's add an engineered feature! You suspect that there is a relationship between the distance between the start and end stations and whether it will be a \"quick\" ride. Let's add the distance between the start station and the end station as a feature. (1 point)**\n","\n","Extend your query from step 3 to also have a feature for the euclidean distance between the start and end station.\n","\n","You may find the following useful:\n","- [Example](https://docs.google.com/presentation/d/10jDyG1TgwB30aNYUdhd9oe7SIQBKkmLMF0Gbq4OU5F0/edit#slide=id.g44a6f5d97e_1_1894) from Dr. Lakshmanan's invited talk\n","- `ST_GeogPoint(longitude, latitude)` - creates geography point from longitude, latitude values\n","- `ST_DISTANCE(start_pt, end_pt)` - computes distance between 2 geographic points (more [here](https://postgis.net/docs/PostGIS_Special_Functions_Index.html#PostGIS_GeographyFunctions))\n","\n","You are welcome, but not required, to experiment with other engineered features as well.\n","\n","Display the first 10 rows of the table returned by your query."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbBZJCa18czi"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","SELECT trip.bikeid, trip.start_station_name, trip.end_station_name, EXTRACT(TIME FROM trip.start_time) AS time, EXTRACT(DAYOFWEEK FROM trip.start_time) AS day, EXTRACT(MONTH FROM trip.start_time) AS month, EXTRACT(YEAR FROM trip.start_time) AS year, trip.subscriber_type, ST_DISTANCE(ST_GEOGPOINT(station1.longitude, station1.latitude), ST_GEOGPOINT(station2.longitude, station2.latitude)) as distance, IF(trip.duration_minutes < 15, 1, 0) AS label\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips` as trip\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station1\n","ON trip.start_station_id = station1.station_id\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station2\n","ON trip.end_station_id = station2.station_id\n","WHERE duration_minutes > 0\n","LIMIT 10"]},{"cell_type":"markdown","metadata":{"id":"ABZT9fAT5Fy3"},"source":["**b) Let's train our model again (using the same training set as before) with the added features. You can replace the existing one, or create a new one with a different name. (1 point)**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kYZNHNqz4p0N"},"source":["**Note**: it may take a few minutes to run the query. Also, you may again get the error `Table has no schema: call 'client.get_table()'`. The model is still trained successfully though. You may ignore this, and can click the (X) in the top left of the output to clear the error message."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgUXMHqYEHeT"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","CREATE OR REPLACE MODEL `bqml_bikeshare.bikeshare_model_v2`\n","OPTIONS(model_type='logistic_reg') AS\n","\n","SELECT trip.bikeid, trip.start_station_name, trip.end_station_name, EXTRACT(TIME FROM trip.start_time) AS time, EXTRACT(DAYOFWEEK FROM trip.start_time) AS day, EXTRACT(MONTH FROM trip.start_time) AS month, EXTRACT(YEAR FROM trip.start_time) AS year, trip.subscriber_type, ST_DISTANCE(ST_GEOGPOINT(station1.longitude, station1.latitude), ST_GEOGPOINT(station2.longitude, station2.latitude)) as distance, IF(trip.duration_minutes < 15, 1, 0) AS label\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips` as trip\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station1\n","ON trip.start_station_id = station1.station_id\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station2\n","ON trip.end_station_id = station2.station_id\n","WHERE duration_minutes > 0 AND EXTRACT(DATE FROM start_time) < '2017-01-01'"]},{"cell_type":"markdown","metadata":{"id":"RkURhcloIBoQ"},"source":["Let's get our training stats again:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQzLy39KIFEc"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# Run cell to view training stats\n","\n","SELECT\n","  *\n","FROM\n","  ML.TRAINING_INFO(MODEL `bqml_bikeshare.bikeshare_model_v2`)"]},{"cell_type":"markdown","metadata":{"id":"1G_Ivatar12p"},"source":["You'll should hopefully find that the loss is a bit lower (better) than before, on both on the training data and on BigQuery's automatic evauation set (it withholds some data you passed in as training data for reporting eval stats)."]},{"cell_type":"markdown","metadata":{"id":"uaf2CD9I5dvN"},"source":["**c) Now let's evaluate our re-trained model on our evaluation set. You can use a similar evaluation query from step 5, but with your updated features (note: you may need to change the model name in the query if your new model has a different name). (1 point)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOxKtiwKbp3Y"},"outputs":[],"source":["%%bigquery --project $project_id\n","# YOUR QUERY HERE\n","\n","\n","SELECT\n","  *\n","FROM\n","  ML.EVALUATE(MODEL `bqml_bikeshare.bikeshare_model_v2`, (SELECT trip.bikeid, trip.start_station_name, trip.end_station_name, EXTRACT(TIME FROM trip.start_time) AS time, EXTRACT(DAYOFWEEK FROM trip.start_time) AS day, EXTRACT(MONTH FROM trip.start_time) AS month, EXTRACT(YEAR FROM trip.start_time) AS year, trip.subscriber_type, ST_DISTANCE(ST_GEOGPOINT(station1.longitude, station1.latitude), ST_GEOGPOINT(station2.longitude, station2.latitude)) as distance, IF(trip.duration_minutes < 15, 1, 0) AS label\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips` as trip\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station1\n","ON trip.start_station_id = station1.station_id\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station2\n","ON trip.end_station_id = station2.station_id\n","WHERE duration_minutes > 0 AND EXTRACT(DATE FROM start_time) BETWEEN '2017-01-01' AND '2017-06-01'))"]},{"cell_type":"markdown","metadata":{"id":"bz512wScoVOs"},"source":["### Step 7: Evaluate final model on test set (1 point)\n","\n","Once you're done training your model (in practice, you'll likely iterate on updating your model, retraining on the training set, and re-evaluating on the evaluation set several times), you'll evaluate your final model on a test set. The test set consists of examples that have not been used at all before,  neither during training nor during evaluation.\n","\n","Again, the test set should **only be used once at the end of your entire training process**, to see how your model does on real data. You should only run the cell below once you are finished modifying your features.\n","\n","Recall that for our test set, we're using the 5 months after our evaluation set (rides with start_time between  '2017-06-01' and  '2017-11-01', with duration time > 0).\n","\n","**Evaluate your model once on this test set. The query is almost identical to the previous one, except now you use the test set.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ubabj72ptCwS"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","SELECT\n","  *\n","FROM\n","  ML.EVALUATE(MODEL `bqml_bikeshare.bikeshare_model_v2`, (SELECT trip.bikeid, trip.start_station_name, trip.end_station_name, EXTRACT(TIME FROM trip.start_time) AS time, EXTRACT(DAYOFWEEK FROM trip.start_time) AS day, EXTRACT(MONTH FROM trip.start_time) AS month, EXTRACT(YEAR FROM trip.start_time) AS year, trip.subscriber_type, ST_DISTANCE(ST_GEOGPOINT(station1.longitude, station1.latitude), ST_GEOGPOINT(station2.longitude, station2.latitude)) as distance, IF(trip.duration_minutes < 15, 1, 0) AS label\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips` as trip\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station1\n","ON trip.start_station_id = station1.station_id\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station2\n","ON trip.end_station_id = station2.station_id\n","WHERE duration_minutes > 0 AND EXTRACT(DATE FROM start_time) BETWEEN '2017-06-01' AND '2017-11-01'))"]},{"cell_type":"markdown","metadata":{"id":"fvBaQkC25iL1"},"source":["### Step 8: Use the trained model to predict (1 point)\n","\n","Once you've trained your model, you can use it to make predictions! Let's try to use it to fill in some of the missing data.\n","\n","**Now, let's go ahead and predict on rides that had a duration time of 0 minutes, but had different start/end stations. Does our model think these were quick rides?**\n","\n","Notice that these samples were never used during training/evaluation/testing, since we filtered out rides with a duration of 0.\n","\n","Display the features used for prediction and the predicted label for 10 examples. The predicted label will be called  `predicted_label.`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kY3B-bGdSu-i"},"outputs":[],"source":["%%bigquery --project $project_id\n","\n","# YOUR QUERY HERE\n","SELECT\n","  bikeid, start_station_name, end_station_name, time, day, month, year, subscriber_type, distance,\n","  predicted_label\n","FROM\n","  ML.PREDICT(MODEL `bqml_bikeshare.bikeshare_model_v2`, (\n","  SELECT trip.bikeid, trip.start_station_name, trip.end_station_name, EXTRACT(TIME FROM trip.start_time) AS time, EXTRACT(DAYOFWEEK FROM trip.start_time) AS day, EXTRACT(MONTH FROM trip.start_time) AS month, EXTRACT(YEAR FROM trip.start_time) AS year, trip.subscriber_type, ST_DISTANCE(ST_GEOGPOINT(station1.longitude, station1.latitude), ST_GEOGPOINT(station2.longitude, station2.latitude)) as distance\n","FROM `cs145-fall2023.austin_bikeshare.austin_bikeshare_trips` as trip\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station1\n","ON trip.start_station_id = station1.station_id\n","JOIN `cs145-fall2023.austin_bikeshare.austin_bikeshare_stations` as station2\n","ON trip.end_station_id = station2.station_id\n","WHERE duration_minutes = 0 AND start_station_id != CAST(end_station_id AS int64)))\n","LIMIT 10;"]}],"metadata":{"colab":{"provenance":[{"file_id":"1lbADxQrvBFLun5Oy_LHX_bih4aI68e-Z","timestamp":1700698872731}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
